{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_curve, \\\n",
    "    plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import sys\n",
    "import warnings\n",
    "from matplotlib.pyplot import figure\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file_path = \"./Economic_data_clean_20200801.xlsx\"\n",
    "\n",
    "csv_data = pd.read_excel(file_path)\n",
    "csv_data['EARN_DOWN'] = csv_data['EARN_DOWN'].astype(np.float16)\n",
    "#complete_data = complete_data.reset_index()\n",
    "#complete_data = complete_data.drop(['index'], axis=1)\n",
    "lags = [10, 30]\n",
    "cols_to_lag = ['CDX_HY', 'CDX_IG']\n",
    "\n",
    "def create_lag_variables(df, lags, cols):\n",
    "    df = df.assign(**{\n",
    "        '{} (t-{})'.format(col, t): csv_data[col].shift(t)\n",
    "        for t in lags\n",
    "        for col in cols_to_lag\n",
    "    })\n",
    "    return df\n",
    "create_lag_variables(csv_data, lags, cols_to_lag)\n",
    "\n",
    "def wavg(group):\n",
    "    group = group.reset_index().drop(['index'], axis=1)\n",
    "    i = 0\n",
    "    weight_sum = 0\n",
    "    for j in range(0, group.shape[0]):\n",
    "        i = i + 1\n",
    "        weight_sum = weight_sum + i\n",
    "#         print(group.iloc[[j]] * i)\n",
    "        group.iloc[[j]] = group.iloc[[j]] * i\n",
    "#     print(group)\n",
    "    return group.iloc[:, :].sum(axis=0) / weight_sum\n",
    "\n",
    "def DataPreprocess(raw_data, back_rows, forward_rows, is_weighted):\n",
    "    raw_data = raw_data.drop(['Dates'], axis=1)\n",
    "    start_index = back_rows\n",
    "    end_index = raw_data.shape[0] - forward_rows + 1\n",
    "    new_rows = []\n",
    "    for i in range(start_index, end_index):\n",
    "        if is_weighted:\n",
    "            new_rows.append(wavg(raw_data.iloc[i-back_rows:i, :]))\n",
    "        else:\n",
    "            new_rows.append(raw_data.iloc[i-back_rows:i, :].mean(axis=0))\n",
    "    training_data = pd.concat(new_rows, axis=1).T\n",
    "    HY_labels = raw_data.iloc[start_index + forward_rows - 1: raw_data.shape[0], [8]].reset_index().drop(['index'], axis=1)\n",
    "    IG_labels = raw_data.iloc[start_index + forward_rows - 1: raw_data.shape[0], [13]].reset_index().drop(['index'], axis=1)\n",
    "    HY_spread_labels = raw_data.iloc[start_index + forward_rows - 1: raw_data.shape[0], [12]].reset_index().drop(['index'], axis=1)\n",
    "    return training_data, HY_labels, IG_labels, HY_spread_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "\n",
    "csv_data['CDX_HY_UpNextDay'] = csv_data['CDX_HY'].shift(-1) > csv_data['CDX_HY']\n",
    "csv_data['CDX_IG_UpNextDay'] = csv_data['CDX_IG'].shift(-1) > csv_data['CDX_IG']\n",
    "\n",
    "csv_data['CDX_HY_momentum'] = csv_data['CDX_HY_10D_AVG'] - csv_data['CDX_HY_30D_AVG'] / csv_data['CDX_HY_30D_AVG']\n",
    "csv_data['CDX_IG_momentum'] = csv_data['CDX_IG_10D_AVG'] - csv_data['CDX_IG_30D_AVG'] / csv_data['CDX_IG_30D_AVG']\n",
    "\n",
    "complete_data = csv_data.dropna()\n",
    "complete_data_bool = complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, HY_labels, IG_labels, HY_spread_labels = DataPreprocess(complete_data, 2, 2, True)\n",
    "\n",
    "complete_data = pd.DataFrame(scale(training_data, axis=0, with_mean=True, with_std=True, copy=True),columns=training_data.columns.values)\n",
    "\n",
    "X = complete_data.drop(['CDX_HY_UpNextDay','CDX_IG_UpNextDay'],axis=1)\n",
    "\n",
    "X_HY = X.drop(['CDX_HY'],axis=1)\n",
    "X_IG = X.drop(['CDX_IG'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1963 entries, 0 to 1962\n",
      "Data columns (total 42 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   10YR_UST                           1963 non-null   float64\n",
      " 1   10_2_Curve                         1963 non-null   float64\n",
      " 2   10_30_Curve                        1963 non-null   float64\n",
      " 3   10_5_Curve                         1963 non-null   float64\n",
      " 4   1YR_SWAP                           1963 non-null   float64\n",
      " 5   2YR_UST                            1963 non-null   float64\n",
      " 6   30YR_UST                           1963 non-null   float64\n",
      " 7   5YR_UST                            1963 non-null   float64\n",
      " 8   CDX_HY                             1963 non-null   float64\n",
      " 9   CDX_HY_10D_AVG                     1963 non-null   float64\n",
      " 10  CDX_HY_30D_AVG                     1963 non-null   float64\n",
      " 11  CDX_HY_5D_AVG                      1963 non-null   float64\n",
      " 12  CDX_HY_SPREAD                      1963 non-null   float64\n",
      " 13  CDX_IG                             1963 non-null   float64\n",
      " 14  CDX_IG_10D_AVG                     1963 non-null   float64\n",
      " 15  CDX_IG_30D_AVG                     1963 non-null   float64\n",
      " 16  CDX_IG_5D_AVG                      1963 non-null   float64\n",
      " 17  CITI_SUPRISE                       1963 non-null   float64\n",
      " 18  EARN_DOWN                          1963 non-null   float64\n",
      " 19  EARN_UP                            1963 non-null   float64\n",
      " 20  FED_BS                             1963 non-null   float64\n",
      " 21  GOLD                               1963 non-null   float64\n",
      " 22  LF98TRUU_Index_ SPREAD_RATE_RATIO  1963 non-null   float64\n",
      " 23  LF98TRUU_Index_DURATION            1963 non-null   float64\n",
      " 24  LF98TRUU_Index_OAS                 1963 non-null   float64\n",
      " 25  LF98TRUU_Index_SPREAD_DUR_RATIO    1963 non-null   float64\n",
      " 26  LF98TRUU_Index_YTW                 1963 non-null   float64\n",
      " 27  LF98TRUU_RATE_COMP                 1963 non-null   float64\n",
      " 28  LUACTRUU_Index_ SPREAD_RATE_RATIO  1963 non-null   float64\n",
      " 29  LUACTRUU_Index_DURATION            1963 non-null   float64\n",
      " 30  LUACTRUU_Index_OAS                 1963 non-null   float64\n",
      " 31  LUACTRUU_Index_SPREAD_DUR_RATIO    1963 non-null   float64\n",
      " 32  LUACTRUU_Index_YTW                 1963 non-null   float64\n",
      " 33  LUACTRUU_RATE_COMP                 1963 non-null   float64\n",
      " 34  OIL                                1963 non-null   float64\n",
      " 35  S&P500                             1963 non-null   float64\n",
      " 36  UNEMPLOY_NUM                       1963 non-null   float64\n",
      " 37  VIX_INDEX                          1963 non-null   float64\n",
      " 38  CDX_HY_UpNextDay                   1963 non-null   float64\n",
      " 39  CDX_IG_UpNextDay                   1963 non-null   float64\n",
      " 40  CDX_HY_momentum                    1963 non-null   float64\n",
      " 41  CDX_IG_momentum                    1963 non-null   float64\n",
      "dtypes: float64(42)\n",
      "memory usage: 644.2 KB\n"
     ]
    }
   ],
   "source": [
    "complete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1966 entries, 29 to 1994\n",
      "Data columns (total 43 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   Dates                              1966 non-null   datetime64[ns]\n",
      " 1   10YR_UST                           1966 non-null   float64       \n",
      " 2   10_2_Curve                         1966 non-null   float64       \n",
      " 3   10_30_Curve                        1966 non-null   float64       \n",
      " 4   10_5_Curve                         1966 non-null   float64       \n",
      " 5   1YR_SWAP                           1966 non-null   float64       \n",
      " 6   2YR_UST                            1966 non-null   float64       \n",
      " 7   30YR_UST                           1966 non-null   float64       \n",
      " 8   5YR_UST                            1966 non-null   float64       \n",
      " 9   CDX_HY                             1966 non-null   float64       \n",
      " 10  CDX_HY_10D_AVG                     1966 non-null   float64       \n",
      " 11  CDX_HY_30D_AVG                     1966 non-null   float64       \n",
      " 12  CDX_HY_5D_AVG                      1966 non-null   float64       \n",
      " 13  CDX_HY_SPREAD                      1966 non-null   float64       \n",
      " 14  CDX_IG                             1966 non-null   float64       \n",
      " 15  CDX_IG_10D_AVG                     1966 non-null   float64       \n",
      " 16  CDX_IG_30D_AVG                     1966 non-null   float64       \n",
      " 17  CDX_IG_5D_AVG                      1966 non-null   float64       \n",
      " 18  CITI_SUPRISE                       1966 non-null   float64       \n",
      " 19  EARN_DOWN                          1966 non-null   float16       \n",
      " 20  EARN_UP                            1966 non-null   int64         \n",
      " 21  FED_BS                             1966 non-null   float64       \n",
      " 22  GOLD                               1966 non-null   float64       \n",
      " 23  LF98TRUU_Index_ SPREAD_RATE_RATIO  1966 non-null   float64       \n",
      " 24  LF98TRUU_Index_DURATION            1966 non-null   float64       \n",
      " 25  LF98TRUU_Index_OAS                 1966 non-null   float64       \n",
      " 26  LF98TRUU_Index_SPREAD_DUR_RATIO    1966 non-null   float64       \n",
      " 27  LF98TRUU_Index_YTW                 1966 non-null   float64       \n",
      " 28  LF98TRUU_RATE_COMP                 1966 non-null   float64       \n",
      " 29  LUACTRUU_Index_ SPREAD_RATE_RATIO  1966 non-null   float64       \n",
      " 30  LUACTRUU_Index_DURATION            1966 non-null   float64       \n",
      " 31  LUACTRUU_Index_OAS                 1966 non-null   float64       \n",
      " 32  LUACTRUU_Index_SPREAD_DUR_RATIO    1966 non-null   float64       \n",
      " 33  LUACTRUU_Index_YTW                 1966 non-null   float64       \n",
      " 34  LUACTRUU_RATE_COMP                 1966 non-null   float64       \n",
      " 35  OIL                                1966 non-null   float64       \n",
      " 36  S&P500                             1966 non-null   float64       \n",
      " 37  UNEMPLOY_NUM                       1966 non-null   float64       \n",
      " 38  VIX_INDEX                          1966 non-null   float64       \n",
      " 39  CDX_HY_UpNextDay                   1966 non-null   bool          \n",
      " 40  CDX_IG_UpNextDay                   1966 non-null   bool          \n",
      " 41  CDX_HY_momentum                    1966 non-null   float64       \n",
      " 42  CDX_IG_momentum                    1966 non-null   float64       \n",
      "dtypes: bool(2), datetime64[ns](1), float16(1), float64(38), int64(1)\n",
      "memory usage: 637.4 KB\n"
     ]
    }
   ],
   "source": [
    "complete_data_bool.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data\n",
    "print(\"Splitting Test and Training Data...\")\n",
    "X_HY_train, X_HY_test, Y_HY_train, Y_HY_test = train_test_split(X_HY, Y_HY, test_size=.25)\n",
    "X_IG_train, X_IG_test, Y_IG_train, Y_IG_test = train_test_split(X_IG, Y_IG, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Target\n",
    "print(\"Encoding target data...\")\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "Y_HY_train_encoded = lab_enc.fit_transform(Y_HY_train)\n",
    "Y_IG_train_encoded = lab_enc.fit_transform(Y_IG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the HY models...\")\n",
    "AB_model_HY = AdaBoostClassifier().fit(X_HY_train, Y_HY_train_encoded)\n",
    "print(\"Training the IG models...\")\n",
    "AB_model_IG = AdaBoostClassifier().fit(X_IG_train, Y_IG_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.DataFrame(AB_model_HY.feature_importances_, columns=['Feature Importance'], index=X_HY_train.columns)\n",
    "feat_impt = feat_impt.sort_values('Feature Importance', ascending=True)\n",
    "feat_impt.plot(kind='barh', figsize=(10, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.DataFrame(AB_model_IG.feature_importances_, columns=['Feature Importance'], index=X_IG_train.columns)\n",
    "feat_impt = feat_impt.sort_values('Feature Importance', ascending=True)\n",
    "feat_impt.plot(kind='barh', figsize=(10, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_IG_forrest = RandomForestClassifier()\n",
    "clf_HY_forrest = RandomForestClassifier()\n",
    "\n",
    "#Depreciated\n",
    "drop_list = []\n",
    "\n",
    "# Fit the model\n",
    "print(\"Fitting IG Random Forrest Model...\")\n",
    "clf_IG_forrest.fit(X_IG_train, Y_IG_train_encoded.ravel())\n",
    "      \n",
    "print(\"Fitting HY Random Forrest Model...\")\n",
    "clf_HY_forrest.fit(X_HY_train, Y_HY_train_encoded.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print IG Features\n",
    "def print_IG_features():\n",
    "    \n",
    "    features_IG = np.array(X_IG_train.columns)\n",
    "    features_IG = list(features_IG)\n",
    "\n",
    "    for item in drop_list:\n",
    "        features_IG.remove(item)\n",
    "\n",
    "    features_IG = np.array(features_IG) \n",
    "    figure(num=None, figsize=(11, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    importances = clf_IG_forrest.feature_importances_\n",
    "    sorted_idx = np.argsort(importances)\n",
    "    padding = np.arange(len(features_IG)) + 0.5\n",
    "    pl.barh(padding, importances[sorted_idx], align='center')\n",
    "    pl.yticks(padding, features_IG[sorted_idx])\n",
    "    pl.xlabel(\"Relative Importance\")\n",
    "    pl.title(\"Variable Importance for CDX.IG\")\n",
    "    pl.show()\n",
    "        \n",
    "print_IG_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print IG Features\n",
    "def print_HY_features():\n",
    "    \n",
    "    features_IG = np.array(X_IG_train.columns)\n",
    "    features_IG = list(features_IG)\n",
    "\n",
    "    for item in drop_list:\n",
    "        features_IG.remove(item)\n",
    "\n",
    "    features_IG = np.array(features_IG) \n",
    "    figure(num=None, figsize=(11, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    importances = clf_HY_forrest.feature_importances_\n",
    "    sorted_idx = np.argsort(importances)\n",
    "    padding = np.arange(len(features_IG)) + 0.5\n",
    "    pl.barh(padding, importances[sorted_idx], align='center')\n",
    "    pl.yticks(padding, features_IG[sorted_idx])\n",
    "    pl.xlabel(\"Relative Importance\")\n",
    "    pl.title(\"Variable Importance for CDX.HY\")\n",
    "    pl.show()\n",
    "        \n",
    "print_HY_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_IG_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB_model_IG = AdaBoostClassifier().fit(X_IG_train, Y_IG_train_encoded)\n",
    "\n",
    "Y_HY_test_encoded = lab_enc.fit_transform(Y_HY_test)\n",
    "Y_IG_test_encoded = lab_enc.fit_transform(Y_IG_test)\n",
    "\n",
    "Y_IG_pred = clf_IG_forrest.predict(X_IG_test)\n",
    "plot_roc_curve(clf_IG_forrest, X_IG_test, Y_IG_test_encoded)\n",
    "area_roc = roc_auc_score(Y_IG_test, Y_IG_pred)\n",
    "plt.title(\"{}, area under ROC: {:.2%}\".format('Adaboost', area_roc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
